
import matplotlib.pyplot as plt
import numpy as np
from sklearn.cross_validation import train_test_split 
import pandas as pd
from numpy import genfromtxt
from scipy.stats import multivariate_normal
from sklearn.metrics import f1_score
from sklearn.model_selection import cross_validate
from sklearn import cross_validation
#from sklearn.model_selection import train_test_split

#define the function for reading our data
def read_dataset(filePath, delimiter=','):
    return genfromtxt(filePath, delimiter=delimiter)

#define paramter for feature normalization
def feature_normalize(dataset):
    mu = np.mean(dataset, axis=0)
    sigma = np.std(dataset, axis=0)
    return (dataset - mu) / sigma

#define the parameter and estimate the Gaussian distribution
def estimate_gaussian(dataset):
    mu = np.mean(dataset, axis=0)
    sigma = np.cov(dataset.T)
    return mu, sigma

def univariate_gaussian(dataset, mu, sigma):
    t=((dataset-mu)**2)/(2*(sigma*sigma))
    q=1/((np.sqrt(2*3.14))*sigma)
    w=q*np.exp(-t)
    return w

#define the multivariate Gaussian distribution
def multivariate_gaussian(dataset, mu, sigma):
    p = multivariate_normal(mean=mu, cov=sigma)
    return p.pdf(dataset)

def select_threshold(probs, test_data):
    best_epsilon = 0
    best_f1 = 0
    f = 0
    stepsize = (max(probs) - min(probs)) / 1000;
    epsilons = np.arange(min(probs), max(probs), stepsize)
    for epsilon in np.nditer(epsilons):
        predictions = (probs < epsilon)
        td = (test_data < epsilon)
        f = f1_score(td, predictions, average='binary')
#        tp=np.sum(np.logical_and(predictions==1,test_data>epsilon)).astype(float)
#        fp=np.sum(np.logical_and(predictions==1,test_data<=epsilon)).astype(float)
#        fn=np.sum(np.logical_and(predictions==0,test_data>epsilon)).astype(float)
#        
#        precision=tp/(tp+fp)
#        recall=tp/(tp+fn)
#        f=(2*precision*recall)/(precision+recall)
        if f > best_f1:
            best_f1 = f
            best_epsilon = epsilon

    return best_f1, best_epsilon



df=pd.read_csv('AMZND.csv')

X=df['Volume']

X=np.array(X)

#print(X)

from sklearn import preprocessing 

n=preprocessing.scale(X)

n=feature_normalize(X)

X_train,X_temp=cross_validation.train_test_split(n,test_size=0.3)

X_cv,X_test=cross_validation.train_test_split(X_temp,test_size=0.5)

#X_test=X_test[:-1]




#print("X_train",X_train)
#print("X_test",X_test)

#

plt.hist(X_train,bins=100)
plt.show()

mu,sigma=estimate_gaussian(X_train)
#plt.hist(estimate_gaussian(X_train))
#plt.show()

#plt.hist(X_train)

p = multivariate_gaussian(X_train,mu,sigma)
plt.scatter(X_train,p,color='k')
plt.show()
#plt.hist(p,bins=100)
h=np.random.normal(mu,sigma[0][0],1000)
plt.hist(h,bins=100)
plt.show()

g = multivariate_gaussian(h,mu,sigma)
plt.scatter(h,g,color='y')
plt.show()




p_cv = multivariate_gaussian(X_cv,mu,sigma)
p_test = multivariate_gaussian(X_test,mu,sigma)
fscore, ep = select_threshold(p_cv,p_test)
#fscore, ep = select_threshold(p_cv,X_test)
print(fscore, ep)

outliers = np.asarray(np.where(p < ep))

plt.subplot(121)
plt.hist(h,bins=100)
plt.subplot(122)
plt.scatter(h,g,color='y')
plt.show()
